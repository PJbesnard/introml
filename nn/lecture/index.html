<!DOCTYPE html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<style>

@import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz:400,700);
@import url(https://fonts.googleapis.com/css?family=Contrail+One:400,700);

</style>
<link rel="stylesheet" type="text/css" href="./library/common.css" />
<link rel="stylesheet" type="text/css" href="./library/screen.css" media="screen" />
<link rel="stylesheet" type="text/css" href="./library/print.css" media="print" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>

</head>
<section style="text-align:center;padding-top:5em;">
  <h1><span class="green">Neural Network </span></h1></br> <h2><p class="grey">UGE,</h2>
  <a href="http://www.twiter.com/comeetie">@comeetie</a>
</section>



<section>
<h1 class="green" >ML</h1>
<h2> Problems </h2>
<ul>
<li> Supervised
$$\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}\rightarrow\, f(\mathbf{x})\approx y$$
<li> Unsupervised
$$\{\mathbf{x}_1,...,\mathbf{x}_n\}\rightarrow\, f(\mathbf{x}) ?$$
</ul>
</section>
<section>
<h1 class="green" >ML</h1>
<h2> Problems </h2>
But also :
<ul>
<li> Semi-supervised
$$\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}+\{\mathbf{x}_1,...,\mathbf{x}_m\}\rightarrow\,f(\mathbf{x})\approx y$$
<li> Self-supervised
$$\{\mathbf{x}_1,...,\mathbf{x}_n\}\rightarrow \{(\mathbf{x}_1,\tilde{y}_1),...,(\mathbf{x}_n,\tilde{y}_n)\}\rightarrow\,f(\mathbf{x})\approx \tilde{y}$$
<li>Re-inforcement learning $$R(a_t,\mathbf{x}_t)$$
</ul>
</section>


<section>
<h1 class="green" >Supervised </h1>
<ul>
<li> Inputs in input feature space $\mathcal{X}$
<li> Outputs in a target space $\mathcal{Y}$</ul>
</ul>
<h2 class="red"> Goal</h2>
find the link function
$$f:\mathcal{X}\rightarrow\mathcal{Y}$$
or in a more probabilistc setting the conditional law $p(y|\mathbf{x})$ between inputs and outputs.
</section>


<section>
<h1 class="green" >Supervised learning </h1>
Hypothesis Space
<ul>
<li> function $f$ belong to a familly of function $\mathcal{H}$ that depends on the methods (SVM, MLP, Decision Tree, Random Forest,...):
$f\in\mathcal{H}$
<li> Goal find the best $f$ in $\mathcal{H}$
</ul>
<h2 class="red"> Goal minimize generalisation error</h2>
$$R(f)=\mathbb{E}_{\mathcal{X},\mathcal{y}}[L(f(\mathbf{x}),y)]=\int_{\mathcal{X}}\int_{\mathcal{y}}L(f(\mathbf{x}),y)p(\mathbf{x},y)d\mathbf{x}dy$$
$L(.,.)$ : loss function that measure the error of a prediction 
</section>


<section>
<h2 class="red">Empirical risk</h2>
A dataset
$S=(\mathbf{x},y):\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}$
$$R_S(f)=\frac{1}{n}\sum_{i=1}^nL(f(\mathbf{x}_i),y_i)$$
$$\mathbb{E}[R_S(f)]=R(f)$$
</section>

<section>
<h2 class="red">Empirical risk minimisation</h2>
function $f$ is defined by a weight vector $\color{red}{\mathbf{w}}$, 
$$f(\mathbf{x};\color{red}{\mathbf{w}})$$
find the function $f$ (and therefore the parameters (i.e. the wiegths) $\color{red}{\mathbf{w}}$) which minimize the risk on a dataset
$$\color{red}{\mathbf{\hat{w}}}=\arg\min_{\color{red}{\mathbf{w}}}R_{S_a}(\color{red}{\mathbf{w}})=\arg\min_{\color{red}{\mathbf{w}}}\frac{1}{n}\sum_{i=1}^nL(f(\mathbf{x}_i,\color{red}{\mathbf{w}}),y_i)$$
</section>


<section>
<h1 class="green" >Regularisation</h1>
$$\hat{\mathbf{w}}=\arg\min_{\mathbf{w}}\frac{1}{n}\sum_{i=1}^nL(f(\mathbf{x}_i,\mathbf{w}),y_i)+\color{red}{\lambda}.\color{green}{\Omega(\mathbf{w})}$$

<ul>
<li> $L$ : floss function
<li> $\color{green}{\Omega}$ : regularisation terms mesure the complexity of the model
<li> $\color{red}{\lambda}$ : hyper-parameter that define the amount of regularisation
</ul>

</section>


<section>
<h1 class="green" >Trainning set / testing set</h1>
<h3> double descent</h3>
$f(\mathbf{x})=f(\mathbf{x},\color{red}{\mathbf{w}})$ more parameters 
<img src="./images/doubledescente.png" height=50%>
<span class="red"> ! for some models like  (NN)  + optimization with SGD like algorithm, 2 regimes 
</section>

<section>
<h1 class="green" >Supervised learning in practive</h1>
<h2 class="red"> Data :</h2>  
 $(\mathbf{x},y):\{(\mathbf{x}_1,y_1),...,(\mathbf{x}_n,y_n)\}$ splited in several parts: </br></br>
<ul>
<li> training set ($S_a$, allow to find $f$)
<li> validation set ($S_v$, allow to compare models /architecture and set the hyper-parameters $\mathcal{H}$)
<li> test set ($S_t$, final evaluation of $f$)
</ul>
</section>




<section style="padding-top:5em;text-align:center">
<h1 class="green">NN</h1>
</section>

<section style="padding-top:5em;text-align:center">
<h1 class="green">Neural Networks</h1>
</section>


<section>
<h2> Un peu d'histoire</h2>
<ul>
<li>1943 : Formal neuron (Mc Culloch & Pitts)
<li>1957 : Perceptron (Rosenblatt)
<li>1969 : Limitation of the perceptron (Minsky & Papert)
<li>1974 : Gradient back-propagation (Werbos, pas de difusion) 
<li> 1986 : Gradient back-propagation bis (Rumelhart & McClelland, Lecun)
<ul>
<li> New architecture Convolutional NN
<li> New applications (Character recognition, Speech recognition and synthesis, Vision (image processing) CNN
</ul>
<li> 1997 : LSTM (Hochreiter & Schmidhuber) 
<li> 2005 : Deep networks (Hinton & Salakhutdinov, 2006)
<li> 2010 : auto-diff (Theano, Bengio & al)
<li> 2014 : Generative Adversarial Networks, GAN (Goodfellow & al)
</ul>
</section>

<section>
<h1 class="green" >Formal Neuron ?</h1>

McCulloch, W. S., Pitts, W., A Logical Calculus of the Ideas Immanent in Nervous Activity, Bulletin of Mathematical Biophysics, vol. 5, pp. 115-133, 1943.

$$\mathbb{R}^p\rightarrow\mathbb{R}$$

$$s=\Phi(\mathbf{x}^t\mathbf{w}+b)$$

linear transformation followed by a non linear transform $\Phi$ :
<ul>
  <li> inputs : $[x_1,...x_p]$ </li>
  <li> weights  : $[w_1,...,w_p]$ et biais : $b$ (memory)</li>
  <li> activation function : $\Phi$</li>
  <li> output : $s$ </li>
</ul>

<h3 class="red"> building block of neural network</h3>

</section>

<section >
<h1 class="green" >Formal neuron ?</h1>


$$\Phi(\mathbf{w}^t\mathbf{x}+b)$$

linear transformation followed by a non linear transform $\Phi$ :
<ul>
  <li> hyperbolique tangente $\Phi(x)$ : $tanh(x)$ </li>
  <li> sigmoid $\Phi(x)$ : $1/(1+\exp(- x))$</li>
  <li> relu $\Phi(x)$ : $max(0,x)$</li>
  <li> ...
  <li> softmax (vectorielle) : $\Phi(\mathbf{x})$ : $[\frac{\exp(\mathbf{x}_1)}{\sum_{k=1}^K\exp(\mathbf{x}_k)},...,\frac{\exp(\mathbf{x}_K)}{\sum_k={1^K}\exp(\mathbf{x}_k)}]$ </li>
</ul>
<h3 class="red"> building block of neural network</h3>

</section> 


<section >
<h1 class="green" >Activation</h1>


<h3 class="red"> Hyperbolic Tangeante </h3>
<img src="./images/Activation_tanh.svg" height="50%"></img>

</section> 

<section >
<h1 class="green" >Activation</h1>

<h3 class="red"> Sigmoid </h3><img src="./images/Activation_logistic.svg" height="50%"></img>

</section> 

<section >
<h1 class="green" >Activation</h1>


</h3><h3 class="red"> ReLu </h3>
<img src="./images/Activation_rectified_linear.svg" height="50%"></img>

</section> 



<section >

<h1 class="green" >MLP</h1>
Multi-layer perceptron. neurones are arranged in layers from <span class="red">inputs $\mathbf{x}$</span> to <span class="green">outputs $\mathbf{y}$</span>
<img src="./images/Colored_neural_network.svg" height="40%"></img>
Network Weights: $\mathbf{W} = [(\mathbf{w}^1,b^1)...,(\mathbf{w}^M,b^m)]$
</section>

<section >
<h1 class="green" >MLP</h1>
Multi-layer perceptron. neurones are arranged in layers from <span class="red">inputs $\mathbf{x}$</span> to <span class="green">outputs $\mathbf{y}$</span>
<img src="./images/Colored_neural_network.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})_r=\Phi^2(b_r^2+\sum_{q=1}^Qw_{rq}^2\Phi^1(b_q^1+\sum_{p=1}^Pw_{qp}^1x_{p}))$$
</section>


<section >
<h1 class="green" >MLP</h1>
Multi-layer perceptron. neurones are arranged in layers from <span class="red">inputs $\mathbf{x}$</span> to <span class="green">outputs $\mathbf{y}$</span>
<img src="./images/Colored_neural_network.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})=\Phi^2(\mathbf{W}^2\Phi^1(\mathbf{W}^1x))$$
</section>

<section >
<h1 class="green" >MLP</h1>
Multi-layer perceptron. neurones are arranged in layers from <span class="red">inputs $\mathbf{x}$</span> to <span class="green">outputs $\mathbf{y}$</span>
<img src="./images/Colored_neural_network_2.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})_r=\Phi^3(b_r^3+\sum_{q=1}^Qw_{rq}^3\Phi^2(b_r^2+\sum_{q=1}^Qw_{rq}^2\Phi^1(b_q^1+\sum_{p=1}^Pw_{qp}^1x_{p})))$$
</section>

<section >
<h1 class="green" >MLP</h1>
Multi-layer perceptron. neurones are arranged in layers from <span class="red">inputs $\mathbf{x}$</span> to <span class="green">outputs $\mathbf{y}$</span>
<img src="./images/Colored_neural_network_2.svg" height="40%"></img>
$$G(\mathbf{x},\mathbf{W})=\Phi^3(\mathbf{W}^3\Phi^2(\mathbf{W}^2\Phi^1(\mathbf{W}^1x)))$$
</section>



<section >
<h1 class="green" >MLP</h1>

<span class="red">Architecture :</span>
<ul>
<li> Number of layer 
<li> Width of the layers
<li> Activation function
<li> Regularisation
<li> <span class="red">Loss function </span>
<ul>
<li> Regression : mse $L=\sum_{i=1}^N||G(\mathbf{x}_i)-y_i||^2$, mae $L=\sum_{i=1}^N|G(\mathbf{x}_i)-y_i|$ 
<li> Classification : cce $L=-\sum_{i=1}^N(y_i\log(G(\mathbf{x}_i))+(1-y_i)log(1-G(\mathbf{x}_i)))$
</ul>
<li>Last layer
<ul>
<li> Regression : linear
<li> Classification : sigmoid (binary), soft-max (mulitclass) 
<ul>
</section>

<section >

<h1 class="green" >MLP</h1>
<h3 class="red">Learning</h3>
<ul>
<li> weights  optimization to minimize $L(G(\mathbf{x},\mathbf{w}),y))$ for a given training set $\{(x_1,y_1),...,(x_n,y_n)\}$
<li> Stochastic gradient descent
<li> gradients $[\frac{\delta L(\mathbf{w})}{\delta W_{11}}, ..., \frac{\delta L(\mathbf{w})}{\delta W_{ld}}]$ can be efficiently computed thanks to the chain rule : 
$$f(g(x))'=f'(g(x))g'(x)$$
i.e. Back-propagation
</ul>
</section>

<section >
<h3>Gradient descent</h3>
update formula :
$$\mathbf{w} \leftarrow \mathbf{w}-\color{red}\lambda\frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}$$
<img src="./images/gradient.png" height="65%"></img>
</section>


<section >

<h3>Gradient descent</h3>
update formula :

$$\mathbf{w} \leftarrow \mathbf{w}-\color{red}\lambda\frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}$$
<ul>
<li> compute the gradient $\frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}$
<li> update the weights by performing a step of size  $\color{red}{\lambda}$
<li> in the opposite direction of the gradient 
<li> // steepest descent direction
<li> iterate until convergence
<ul>

if $\lambda$ small enough will converge to a minima
</section>



<section >


<h3>Gradient descent</h3>
update formula :

Initialize $\mathbf{w}_1$ et $\lambda=0.001$, $\alpha=0.1,L_{old}=-\infty$</br></br>
while $|L(\mathbf{w}_{n})-L_{old}|>\epsilon$:
<ul>
<li> update the wieghts :
$$\mathbf{w}_{n+1} \leftarrow \mathbf{w}_n-\color{red}\lambda\frac{\delta L(\mathbf{w}_n)}{\delta \mathbf{w}}$$
<li> $L_{old} \leftarrow L(\mathbf{w}_n)$
<li> decreasing test if $L(\mathbf{w}_{n+1}) > L_{old}$
<ul>
<li> step size reduction $\lambda \leftarrow\lambda\alpha$ 
</ul>
<li> $n\leftarrow n+1$
<ul>
</section>


<section>
<img src="images/grad1.png" width="60%"></img>
Convexe problem
</section>

<section>
<img src="images/grad2.png" width="60%"></img>
Non convex problem $\rightarrow$ local minima
</section>


<section>
<img src="images/grad3.png" width="60%"></img>
convex problem
</section>

<section>
<img src="images/grad4.png" width="60%"></img>
Non convex problem $\rightarrow$ local minima (final solution initialization dependant)
</section>

<section>
<img src="images/grad5.png" width="60%"></img>
Non convex problem $\rightarrow$ local minima (final solution initialization dependant)
</section>

<section >

<h1>Stochastic gradient descent</h1>
$$\frac{1}{\color{green}{n_b}}\sum_{i \in \color{green}{\mathbb{B}_j}} L(G(\mathbf{x}_i,\mathbf{w}),y_i) \approx \frac{1}{N} \sum_{i=1}^N L(G(\mathbf{x}_i,\mathbf{w}),y_i)$$

<ul>
<li> Perform $m$ epochs (a complet scan of the training set):   
<li> shuffle the training set
<li> split in mini batch (mini-batch $\color{green}{\mathbb{B}_j}$) of size $\color{green}{n_b}$
<li> for each mini-batch update the weights with the gradients computed on the mini-batch 

</ul>
</br>
<span class="red">Online gradient, mini-batch of size $n_b=1$</span></br>
<span class="red">$\Rightarrow$Small complexity, works with huge datasets </span></br>

</section>

<section>
<h1>Momentum</h1>
<span class="red">$\Rightarrow$Variantes that take into acount the dynamic of the updates (add some intertia in the updates):</br>
 rmsprop, Adam,...</span>
$$
\begin{align}
\mathbf{z}_{n+1} &= \beta \mathbf{z}_{n} + \frac{\delta L(\mathbf{w})}{\delta \mathbf{w}}\nonumber\\
\mathbf{w}_{n+1} &= \mathbf{w}_{n} -\lambda \mathbf{z}_{n+1}\nonumber
\end{align}
$$

<ul>
<li><a href="https://distill.pub/2017/momentum/">https://distill.pub/2017/momentum/</a>
<li><a href="https://ruder.io/optimizing-gradient-descent/">https://ruder.io/optimizing-gradient-descent/</a>
</ul>
</section>



<section >
<h3>Neural Network Libraries</h3>
<h2 class="red">Back Propagation -> automatic differentiation</h2>
Reverse mode automatic differentiation
Define the network architectecture, the libraries will automaticaly create function to compute the gradients 
<ul>
<li> Theano
<li> Torch
<li> TensorFlow
<li> ...
<ul> 
</section>







<section>
<h1 class="green">Keras</h1>
<h1><a href="https://keras.io/">https://keras.io/</a></h1>
</section>

<section >
<h1>Keras</h1>
</br>
high level librairy to define nn and learn their parameters </br>
//Sequential interface
<pre><code class="python">model = Sequential()
model.add(Dense(32, activation='relu', input_dim=100))
model.add(Dense(10, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Generate dummy data
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(10, size=(1000, 1))

# Convert labels to categorical one-hot encoding
one_hot_labels = keras.utils.to_categorical(labels, num_classes=10)

# Train the model, iterating on the data in batches of 32 samples
model.fit(data, one_hot_labels, epochs=10, batch_size=32)
</pre></code>
</section>

<section >
<h1>Keras</h1>
high level librairy to define nn and learn their parameters </br>
//Functional Interface 
<pre><code class="python">from keras.layers import Input, Dense
from keras.models import Model
# This returns a tensor
inputs = Input(shape=(784,))
# a layer instance is callable on a tensor, and returns a tensor
h1 = Dense(64, activation='relu')(inputs)
h2 = Dense(64, activation='relu')(h1)
predictions = Dense(10, activation='softmax')(h2)
# This creates a model that includes
# the Input layer and three Dense layers
model = Model(inputs=inputs, outputs=predictions)
model.compile(optimizer='rmsprop',loss='categorical_crossentropy')
model.fit(data, labels)  # starts training
</pre></code>
</section>


<section>
<img src="./images/tensorplay.png" width="85%">
<a href="http://playground.tensorflow.org">http://playground.tensorflow.org</a>
</section>

<section>
<h1> Links and ressources </h1>

& images credits 

<ul>
<li><a href="https://www.tensorflow.org/tutorials">https://www.tensorflow.org/tutorials</a>

<li> <a href="https://stanford.edu/~shervine/teaching/cs-230/"> standford cs230 </a>

<li> <a href="https://github.com/rasbt/stat453-deep-learning-ss20"> stat 453 </a>

<li> <a href="https://atcold.github.io/pytorch-Deep-Learning/"> course yann lecun </a>
 
<li> <a href="https://moodle.insa-rouen.fr/course/view.php?id=1207">romain herault insa </a>

<li><a href="https://drive.google.com/file/d/1e_9W8q9PL20iqOR-pfK89eILc_VtYaw1/view"> Gradient-based Optimization in deep learning </a>



</ul>


</section>




<script src="./library/d3.v3.min.js"></script>
<script src="./library/stack.v1.min.js"></script>
<link rel="stylesheet" href="./library/styles/hybrid.css">
<script src="./library/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script>

var mystack = stack()
    .on("activate", activate)
    .on("deactivate", deactivate);

var section = d3.selectAll("section"),
    follow = d3.select("#follow"),
    followAnchor = d3.select("#follow-anchor"),
    lorenz = d3.select("#lorenz"),
    followIndex = section[0].indexOf(follow.node()),
    lorenzIndex = section[0].indexOf(lorenz.node());

function refollow() {
  followAnchor.style("top", (followIndex + (1 - mystack.scrollRatio()) / 2 - d3.event.offset) * 100 + "%");
}

function activate(d, i) {
  if (i === followIndex) mystack.on("scroll.follow", refollow);
  if (i === lorenzIndex) startLorenz();
}

function deactivate(d, i) {
  if (i === followIndex) mystack.on("scroll.follow", null);
  if (i === lorenzIndex) stopLorenz();
}


</script>
